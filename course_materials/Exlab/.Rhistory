data_cleaned <- filter(data_raw, outlier==FALSE)
head(data_cleaned)
message(
"We excluded", sum(data_indi_summary$outlier),
"participants for suspecious mean RTs and higher error rates."
)
message(
"We excluded ", sum(data_indi_summary$outlier),
" participants for suspecious mean RTs and higher error rates."
)
data %>% ggplot(aes(x=log(RT))) + geom_histogram() +
geom_jitter(aes(x = RT, y = 1), alpha = 0.3, height = 300)
data_cleaned %>% ggplot(aes(x=log(RT))) + geom_histogram() +
geom_jitter(aes(x = RT, y = 1), alpha = 0.3, height = 300)
data_cleaned %>% ggplot(aes(x=log(RT))) + geom_histogram() +
geom_jitter(aes(x = log(RT), y = 1), alpha = 0.3, height = 300)
data_cleaned <- filter(data_cleaned, RT > 100 & RT < 1000) # cleaning the data on a trial level
data_cleaned %>% ggplot(aes(x = RT)) + geom_histogram() + geom_jitter(
aes(x = RT, y = 1), alpha = 0.3, height = 300
)
date_cleaned_sum <- data_cleaned %>% filter(correctness == "correct") %>% group_by(condition) %>%
summarize(mean_RT = mean(RT), sd_RT = sd(RT))
head(data_cleaned_sum)
date_cleaned_sum <- data_cleaned %>% filter(correctness == "correct") %>% group_by(condition) %>%
summarize(mean_RT = mean(RT), sd_RT = sd(RT))
head(data_cleaned_sum)
head(date_cleaned_sum)
aes(y = 0.0005), alpha = 0.2, height = 0.0005) + # add individual data points
geom_density(fill = "gray", alpha = 0.5) + # add a denity plot
geom_vline(data = date_cleaned_sum, mapping = aes(xinterpret = mean_RT), color = "firebrick") +
facet_grid(condition ~ .)
aes(y = 0.0005), alpha = 0.2, height = 0.0005) + # add individual data points
geom_density(fill = "gray", alpha = 0.5) + # add a denity plot
geom_vline(data = date_cleaned_sum, mapping = aes(xintercep = mean_RT), color = "firebrick") +
facet_grid(condition ~ .)
aes(y = 0.0005), alpha = 0.2, height = 0.0005) + # add individual data points
geom_density(fill = "gray", alpha = 0.5) + # add a denity plot
geom_vline(data = date_cleaned_sum, mapping = aes(xintercept = mean_RT), color = "firebrick") +
facet_grid(condition ~ .)
#plotting the reaction time
date_cleaned %>%
filter(correctness == "correct") %>%
ggplot(aes(x = RT)) +
geom_jitter(aes(y = 0.0005), alpha = 0.2, height = 0.0005) + # add individual data points
geom_density(fill = "gray", alpha = 0.5) + # add a denity plot
geom_vline(data = date_cleaned_sum, mapping = aes(xintercept = mean_RT), color = "firebrick") +
facet_grid(condition ~ .)
#plotting the reaction time
data_cleaned %>%
filter(correctness == "correct") %>%
ggplot(aes(x = RT)) +
geom_jitter(aes(y = 0.0005), alpha = 0.2, height = 0.0005) + # add individual data points
geom_density(fill = "gray", alpha = 0.5) + # add a denity plot
geom_vline(data = date_cleaned_sum, mapping = aes(xintercept = mean_RT), color = "firebrick") +
facet_grid(condition ~ .)
#plotting the reaction time
data_cleaned %>%
filter(correctness == "correct") %>%
ggplot(aes(x = RT)) +
geom_jitter(aes(y = 0.0005), alpha = 0.1, height = 0.0005) + # add individual data points
geom_density(fill = "gray", alpha = 0.5) + # add a denity plot
geom_vline(data = date_cleaned_sum, mapping = aes(xintercept = mean_RT), color = "firebrick") +
facet_grid(condition ~ .)
#plotting the reaction time
data_cleaned %>%
filter(correctness == "correct") %>%
ggplot(aes(x = RT)) +
geom_jitter(aes(y = 0.0005), alpha = 0.1, height = 0.0002) + # add individual data points
geom_density(fill = "gray", alpha = 0.5) + # add a denity plot
geom_vline(data = date_cleaned_sum, mapping = aes(xintercept = mean_RT), color = "firebrick") +
facet_grid(condition ~ .)
#plotting the reaction time
data_cleaned %>%
filter(correctness == "correct") %>%
ggplot(aes(x = RT)) +
geom_jitter(aes(y = 0.0005), alpha = 0.1, height = 0.0005) + # add individual data points
geom_density(fill = "gray", alpha = 0.5) + # add a denity plot
geom_vline(data = date_cleaned_sum, mapping = aes(xintercept = mean_RT), color = "firebrick") +
facet_grid(condition ~ .)
#plotting the reaction time
data_cleaned %>%
filter(correctness == "correct") %>%
ggplot(aes(x = RT)) +
geom_jitter(aes(y = 0.0005), alpha = 0.1, height = 0.0005) + # add individual data points
geom_density(fill = "gray", alpha = 0.5) + # add a denity plot
#geom_vline(data = date_cleaned_sum, mapping = aes(xintercept = mean_RT), color = "firebrick") +
facet_grid(condition ~ .)
head(data_cleaned)
#plotting the reaction time
data_cleaned %>%
filter(correctness == "correct") %>%
ggplot(aes(x = RT)) +
geom_jitter(aes(y = 0.0005), alpha = 0.1, height = 0.0005) + # add individual data points
geom_density(fill = "gray", alpha = 0.5) + # add a denity plot
eaned_sum, mapping = aes(xintercept = mean_RT), color = "firebrick") +
#facet_grid(condition ~ .)
#plotting the reaction time
data_cleaned %>%
filter(correctness == "correct") %>%
ggplot(aes(x = RT)) +
geom_jitter(aes(y = 0.0005), alpha = 0.1, height = 0.0005) + # add individual data points
geom_density(fill = "gray", alpha = 0.5)  # add a denity plot
geom_vline(data = date_cleaned_sum, mapping = aes(xintercept = mean_RT), color = "firebrick") +
facet_grid(condition ~ .) #producing facets for each condition
#plotting the reaction time
data_cleaned %>%
filter(correctness == "correct") %>%
ggplot(aes(x = RT)) +
geom_jitter(aes(y = 0.0005), alpha = 0.1, height = 0.0005) + # add individual data points
geom_density(fill = "gray", alpha = 0.5)+  # add a denity plot
geom_vline(data = date_cleaned_sum, mapping = aes(xintercept = mean_RT), color = "firebrick") +
facet_grid(condition ~ .) #producing facets for each condition
library(tidyverse)
library(brms)
# option for bayesian regression models
# use all avaliable cores for parallel computing
library(mc.cores = parallel::detectCores())
library(HDIntervall)
set.seed(1702)
install.packages(brms)
install.packages(brms)
install.packages('brms')
# option for bayesian regression models
# use all avaliable cores for parallel computing
library(mc.cores = parallel::detectCores())
install.packages("mc.cores = parallel::detectCores()")
install.packages("HDIntervall")
setRepositories()
# option for bayesian regression models
# use all avaliable cores for parallel computing
options(mc.cores = parallel::detectCores())
library(HDInterval)
install.packages(HDInterval)
install.packages('HDInterval')
library(HDInterval)
#### import data ####
politedata = read.csv("https://tinyurl.com/polite-data")
head(politedata)
View(politedata)
#### explaore main data ####
politedata %>% pull(pitch) %>% group_by(gender) %>% summarise()
View(date_cleaned_sum)
View(date_cleaned_sum)
View(data_cleaned)
View(data_cleaned)
#### explaore main data ####
po_sum <- politedata %>% pull(pitch) %>% group_by(gender) %>% summarise()
#### explaore main data ####
po_sum <- politedata %>% group_by(gender) %>% summarise(mean_p = mean(pitch), sd_RT = sd(pitch))
View(po_sum)
View(po_sum)
#### explaore main data ####
po_gen_sum <- politedata %>% group_by(gender) %>% summarise(mean_p = mean(pitch), sd_RT = sd(pitch))
po_pi_sum <- politedata %>% group_by(context) %>% summarise(mean_p = mean(pitch), sd_RT = sd(pitch))
View(po_pi_sum)
View(po_pi_sum)
formula_FE = pitch ~ gender * context
model_EF = brm(
formula = formula_FE,
data = politedata,
seed = 1702
)
library(brms)
## modelling data##
formula_FE = pitch ~ gender * context
model_EF = brm(
formula = formula_FE,
data = politedata,
seed = 1702
)
library(tidyverse)
library(brms)
# option for bayesian regression models
# use all avaliable cores for parallel computing
options(mc.cores = parallel::detectCores())
library(HDInterval)
# set random seed in order to make sure one can reproduce same results
set.seed(1702)
#### import data ####
politedata = read.csv("https://tinyurl.com/polite-data")
#### explaore main data ####
po_gen_sum <- politedata %>% group_by(gender) %>% summarise(mean_p = mean(pitch), sd_RT = sd(pitch))
po_pi_sum <- politedata %>% group_by(context) %>% summarise(mean_p = mean(pitch), sd_RT = sd(pitch))
## modelling data##
formula_FE = pitch ~ gender * context
model_EF = brm(
formula = formula_FE,
data = politedata,
seed = 1702
)
model_EF
View(politedata)
View(politedata)
View(model_EF)
View(model_EF)
View(po_gen_sum)
View(po_gen_sum)
#### check the significance ####
post_samples_EF = posterior_samples(model_EF)
head(post_samples_EF)
mean(post_samples_EF$b_genderM > 0)
mean(post_samples_EF$b_contextpol > 0)
mean(post_samples_EF$b_genderM < 0)
mean(post_samples_EF$b_contextpol < 0)
mean(post_samples_EF$`b_genderM:contextpol`>0)
mean(post_samples_EF$b_genderM < 0) < mean(post_samples_EF$b_contextpol < 0)
mean(post_samples_FE$b_contextpol > post_samples_FE$b_genderM)
mean(post_samples_EF$b_genderM < post_samples_EF$b_contextpol)
#### baysian statistic ####
head(data_cleaned)
#### baysian statistic ####
RT_model <- brm(
formula = RT ~ condition * target_object * target_position,
data = data_cleaned
)
RT_model
View(RT_model)
View(RT_model)
compare_groups(
model = ST_model,
higher = list("condition" = "incongruent"),
lower = list("condition" = "congruent")
)
library(faintr)
install.packages("faintr")
install.packages("faintr")
install.packages("devtools")
install_github(
repo = "michael-franke/bayes_mixed_regression_tutorial",
subdir = "faintr")
library(devtools)
library(usethis)
library(devtools)
library(faintr)
install_github(
repo = "michael-franke/bayes_mixed_regression_tutorial",
subdir = "faintr")
#install_github(
#repo = "michael-franke/bayes_mixed_regression_tutorial",
#subdir = "faintr")
library(faintr)
compare_groups(
model = ST_model,
higher = list("condition" = "incongruent"),
lower = list("condition" = "congruent")
)
compare_groups(
model = RT_model,
higher = list("condition" = "incongruent"),
lower = list("condition" = "congruent")
)
compare_groups(
model = RT_model,
higer = list("target_position" = "right"),
lower = list("target_position" = "left")
)
compare_groups(
model = RT_model,
higher = list("target_position" = "right"),
lower = list("target_position" = "left")
)
compare_groups(
model = RT_model,
higher = list("target_object" = "circle"),
lower = list("target_object"  = "square")
)
compare_groups(
model = RT_model,
higher = list("target_position" = "left"),
lower = list("target_position" = "right")
)
library(faintr)
#### take random effects into consideration ####
model_MAXRE = brm(
formula = pitch ~ gender*context +
(1 | sentences) + (1 | subjects) +
(0 + gender * context | sentences) +
(0 + context | subjects),
data = politedata, control = list(adapt_delta = 0.99)
)
View(politedata)
View(politedata)
#### take random effects into consideration ####
model_MAXRE = brm(
formula = pitch ~ gender*context +
(1 | sentence) + (1 | subject) +
(0 + gender * context | sentence) +
(0 + context | subject),
data = politedata, control = list(adapt_delta = 0.99)
)
model_MAXRE
get_posterior_beliefs_about_hypotheses(model_MAXRE)
get_posterior_beliefs_about_hypotheses(model_MaxRE)
library(faintr)
get_posterior_beliefs_about_hypotheses(model_MaxRE)
install.packages(c("RMariaDB", "RMySQL"))
library(tidyverse)
library(stringi)
#setwd("/Users/Elen/Documents/CogSci/J6+/Course_evaluation/J6plus")
library(RMariaDB)
library(RMySQL)
#setwd("/Users/Elen/Documents/CogSci/J6+/Course_evaluation/J6plus")
setwd("D:/Master/Joint study project/Evaluation/J6plus")
password <- "fj58gu4jf7ez3jff4hdjfe2fh23fhff4x"
MoodleDB <- dbConnect(RMariaDB::MariaDB(), user='moodle', password=password, host='127.0.0.1', port=3306)
password <- "fj58gu4jf7ez3jff4hdjfe2fh23fhff4x"
MoodleDB <- dbConnect(RMariaDB::MariaDB(), user='moodle', password=password, host='127.0.0.1', port=3306)
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(stringi)
#setwd("/Users/Elen/Documents/CogSci/J6+/Course_evaluation/J6plus")
#setwd("D:/Master/Joint study project/Evaluation/J6plus")
library(RMariaDB)
library(RMySQL)
grades <- read.csv("Grades-20200529_0954-comma_separated.csv", na.strings = "-")
str(grades)
summary(grades$First.name)
grades <- grades %>% filter(stri_endswith_fixed(Email.address, "sci.asu.edu.eg")) %>% droplevels()
summary(grades$First.name)
colnames(grades)
colnames(grades)
# Course grades
summary(grades$Course.total..Real.)
boxplot(grades$Course.total..Real., main = "Course grades", ylab = "Scores out of 100")
# Neuroscience
par(mfrow=c(3,1))
barplot(grades$Quiz..Methods.in.Neuroscience...Assessment..Real., main = "Quiz Methods Neuroscience", ylab = "Score out of 10", names.arg = grades$First.name)
barplot(grades$Quiz..Brain.Structure...Assessment..Real., main = "Quiz Brain Structure Neuroscience", ylab = "Score out of 10", names.arg = grades$First.name)
barplot(grades$Quiz..From.Neurons.to.Brain.Functions...Assessment..Real., main = "Quiz Neurons to Brain Functions Neuroscience", ylab = "Score out of 10", names.arg = grades$First.name)
par(mfrow=c(1,3))
boxplot(grades$Quiz..Methods.in.Neuroscience...Assessment..Real., main = "Quiz Methods Neuroscience", ylab = "Score out of 10", ylim = c(5,10))
boxplot(grades$Quiz..Brain.Structure...Assessment..Real., main = "Quiz Brain Structure Neuroscience", ylab = "Score out of 10", ylim = c(5,10))
boxplot(grades$Quiz..From.Neurons.to.Brain.Functions...Assessment..Real., main = "Quiz Neurons to Brain Functions Neuroscience", ylab = "Score out of 10", ylim = c(5,10))
grades.long <- grades %>% pivot_longer(cols = 4:24, names_to = "Assessment", values_to = "Grade", values_drop_na = TRUE) %>% filter(Grade > 0)
grades <- read.csv("Grades-20200605_0756-comma_separated_percentage.csv", na.strings = "-", stringsAsFactors = FALSE)
str(grades)
summary(grades$First.name)
grades <- grades %>% filter(stri_endswith_fixed(Email.address, "sci.asu.edu.eg")) %>% droplevels()
summary(grades$First.name) # Only Egyptian participants
colnames(grades)
grades <- grades %>% filter(Course.total..Percentage. > 0) %>% droplevels()
summary(grades$First.name) # Egyptian students who have completed the course
colnames(grades)
grades <- grades %>% select_if(~sum(!is.na(.)) > 0) # Drop variables with no data
colnames(grades)
View(grades)
# Creating long data frame
grades.long <- grades %>% pivot_longer(cols = 4:18, names_to = "Assessment", values_to = "Grade", values_drop_na = TRUE) %>% filter(Grade > 0)
# Cleaning up factor levels for graphs
grades.long$Grade <- as.numeric(sub(" %", "", grades.long$Grade)) # Convert string percentage characters to numeric vectors without the sign and space
grades.long$Assessment <- stringr::str_remove_all(grades.long$Assessment, c("Percentage|Quiz|Assessment|Cognitive\\.Science\\.")) # Remove unnecessary long words in assessment variable
grades.long$Assessment <- stringr::str_replace_all(grades.long$Assessment, "\\.\\.{1,}", "\\.") # Remove double dots in variable
grades.long$Assessment <- stringr::str_remove(grades.long$Assessment, "^\\.|\\.$") # Remove initial and final dots in some assessment names
grades.long$Assessment <- as.factor(grades.long$Assessment)
grades.long.ind <- grades.long %>% mutate(Assessment = factor(Assessment, levels = c("Brain.Structure", "From.Neurons.to.Brain.Functions", "Methods.in.Neuroscience", "Supervised.Learning", "Unsupervised.Learning", "Deep.Learning", "Introduction.to.linguistics","Psycholinguistics", "Computational.Linguistics"))) %>% drop_na() # This data frame does not include the introduction module "Historical.and.Interdisciplinary.Perspectives" nor does it include the aggregated grades for each module.
library(ggpomological) # https://www.garrickadenbuie.com/project/ggpomological/
install.packages(ggpomological)
install.packages('ggpomological')
colnames(grades)
# Course grades
summary(grades$Course.total..Real.)
boxplot(grades$Course.total..Real., main = "Course grades", ylab = "Scores out of 100")
install.packages("devtools")
devtools::install_github("gadenbuie/ggpomological")
library(ggpomological) # https://www.garrickadenbuie.com/project/ggpomological/
library(bbplot)
install.packages('bbplot')
library(dplyr)
library(ggthemr) # https://github.com/cttobin/ggthemr
devtools::install_github('bbc/bbplot')
ggthemr('grape')
library(bbplot)
library(ggthemr) # https://github.com/cttobin/ggthemr
devtools::install_github('cttobin/ggthemr')
library(ggpomological) # https://www.garrickadenbuie.com/project/ggpomological/
library(bbplot)
library(dplyr)
library(ggthemr) # https://github.com/cttobin/ggthemr
ggthemr('grape')
#https://www.r-graph-gallery.com/48-grouped-barplot-with-ggplot2.html
plot1 <- ggplot(grades.long.ind) +
aes(x = Assessment, y = Grade, fill = First.name) +
geom_bar(position="dodge", stat="identity") +
#scale_color_pomological() + theme_pomological() + theme_pomological_fancy() +
#bbc_style() +
theme(axis.text.x = element_text(angle = 90))
plot1
results <- read.csv("results.csv", na.strings = "NULL")
str(grades)
summary(grades$First.name)
grades <- grades %>% filter(stri_endswith_fixed(Email.address, "sci.asu.edu.eg")) %>% droplevels()
summary(grades$First.name) # Only Egyptian participants
grades <- grades %>% filter(Course.total..Real. > 0) %>% droplevels()
grades <- read.csv("Grades-20200529_0954-comma_separated.csv", na.strings = "-")
str(grades)
summary(grades$First.name)
grades <- grades %>% filter(stri_endswith_fixed(Email.address, "sci.asu.edu.eg")) %>% droplevels()
summary(grades$First.name) # Only Egyptian participants
grades <- grades %>% filter(Course.total..Real. > 0) %>% droplevels()
summary(grades$First.name) # Egyptian students who have completed the course
colnames(grades)
grades <- grades %>% select_if(~sum(!is.na(.)) > 0) # Drop variables with no data
colnames(grades)
#grades <- grades %>% select_if(function(col) {colSums(is.numeric(col)) > 0 | is.factor(col)})
#grades <- grades %>% select_if(is.numeric() && colSums() != 0 | is.character()) # Drop variables with no data
View(grades)
colnames(grades)
# Course grades
summary(grades$Course.total..Real.)
boxplot(grades$Course.total..Real., main = "Course grades", ylab = "Scores out of 100")
# Neuroscience
par(mfrow=c(3,1))
barplot(grades$Quiz..Methods.in.Neuroscience...Assessment..Real., main = "Quiz Methods Neuroscience", ylab = "Score out of 10", names.arg = grades$First.name)
barplot(grades$Quiz..Brain.Structure...Assessment..Real., main = "Quiz Brain Structure Neuroscience", ylab = "Score out of 10", names.arg = grades$First.name)
barplot(grades$Quiz..From.Neurons.to.Brain.Functions...Assessment..Real., main = "Quiz Neurons to Brain Functions Neuroscience", ylab = "Score out of 10", names.arg = grades$First.name)
par(mfrow=c(1,3))
boxplot(grades$Quiz..Methods.in.Neuroscience...Assessment..Real., main = "Quiz Methods Neuroscience", ylab = "Score out of 10", ylim = c(5,10))
boxplot(grades$Quiz..Brain.Structure...Assessment..Real., main = "Quiz Brain Structure Neuroscience", ylab = "Score out of 10", ylim = c(5,10))
boxplot(grades$Quiz..From.Neurons.to.Brain.Functions...Assessment..Real., main = "Quiz Neurons to Brain Functions Neuroscience", ylab = "Score out of 10", ylim = c(5,10))
grades.long <- grades %>% pivot_longer(cols = 4:24, names_to = "Assessment", values_to = "Grade", values_drop_na = TRUE) %>% filter(Grade > 0)
grades <- read.csv("Grades-20200605_0756-comma_separated_percentage.csv", na.strings = "-", stringsAsFactors = FALSE)
str(grades)
summary(grades$First.name)
grades <- grades %>% filter(stri_endswith_fixed(Email.address, "sci.asu.edu.eg")) %>% droplevels()
summary(grades$First.name) # Only Egyptian participants
colnames(grades)
grades <- grades %>% filter(Course.total..Percentage. > 0) %>% droplevels()
summary(grades$First.name) # Egyptian students who have completed the course
colnames(grades)
grades <- grades %>% select_if(~sum(!is.na(.)) > 0) # Drop variables with no data
colnames(grades)
View(grades)
# Creating long data frame
grades.long <- grades %>% pivot_longer(cols = 4:18, names_to = "Assessment", values_to = "Grade", values_drop_na = TRUE) %>% filter(Grade > 0)
# Cleaning up factor levels for graphs
grades.long$Grade <- as.numeric(sub(" %", "", grades.long$Grade)) # Convert string percentage characters to numeric vectors without the sign and space
grades.long$Assessment <- stringr::str_remove_all(grades.long$Assessment, c("Percentage|Quiz|Assessment|Cognitive\\.Science\\.")) # Remove unnecessary long words in assessment variable
grades.long$Assessment <- stringr::str_replace_all(grades.long$Assessment, "\\.\\.{1,}", "\\.") # Remove double dots in variable
grades.long$Assessment <- stringr::str_remove(grades.long$Assessment, "^\\.|\\.$") # Remove initial and final dots in some assessment names
grades.long$Assessment <- as.factor(grades.long$Assessment)
grades.long.ind <- grades.long %>% mutate(Assessment = factor(Assessment, levels = c("Brain.Structure", "From.Neurons.to.Brain.Functions", "Methods.in.Neuroscience", "Supervised.Learning", "Unsupervised.Learning", "Deep.Learning", "Introduction.to.linguistics","Psycholinguistics", "Computational.Linguistics"))) %>% drop_na() # This data frame does not include the introduction module "Historical.and.Interdisciplinary.Perspectives" nor does it include the aggregated grades for each module.
library(ggpomological) # https://www.garrickadenbuie.com/project/ggpomological/
library(bbplot)
library(dplyr)
library(ggthemr) # https://github.com/cttobin/ggthemr
ggthemr('grape')
#https://www.r-graph-gallery.com/48-grouped-barplot-with-ggplot2.html
plot1 <- ggplot(grades.long.ind) +
aes(x = Assessment, y = Grade, fill = First.name) +
geom_bar(position="dodge", stat="identity") +
#scale_color_pomological() + theme_pomological() + theme_pomological_fancy() +
#bbc_style() +
theme(axis.text.x = element_text(angle = 90))
plot1
results <- read.csv("results.csv", na.strings = "NULL")
str(grades)
summary(grades$First.name)
grades <- grades %>% filter(stri_endswith_fixed(Email.address, "sci.asu.edu.eg")) %>% droplevels()
summary(grades$First.name) # Only Egyptian participants
grades <- grades %>% filter(Course.total..Real. > 0) %>% droplevels()
########## import libraries ##########
library(tidyverse)
library(brms)
# option for bayesian regression models
# use all avaliable cores for parallel computing
options(mc.cores = parallel::detectCores())
library(HDInterval)
library(faintr)
# set random seed in order to make sure one can reproduce same results
set.seed(1702)
library(devtools)
library(usethis)
install_github(
repo = "michael-franke/bayes_mixed_regression_tutorial",
subdir = "faintr")
install_github(
repo = "michael-franke/bayes_mixed_regression_tutorial",
subdir = "faintr",
force = TRUE)
library(faintr)
library(devtools)
install.packages("brms")
install.packages("brms")
install.packages("brms")
library(brms)
help('brms')
help('HDInterval')
help('??HDInterval')
library(devtools)
detach("package:devtools", unload = TRUE)
library(devtools)
install.packages('usethis')
install.packages("usethis")
library(faintr)
########## import libraries ##########
library(tidyverse)
# option for bayesian regression models
# use all avaliable cores for parallel computing
options(mc.cores = parallel::detectCores())
library(brms)
install.packages('Rcpp')
install.packages("Rcpp")
library(HDInterval)
library(faintr)
library(devtools)
library(usethis)
library(devtools)
# set random seed in order to make sure one can reproduce same results
set.seed(1702)
library(lme4)
library(Matrix)
library(lme4)
